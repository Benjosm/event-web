1. High Level Project Design (What it is and does)\nProduct Name: Global Pulse\n\nDescription: A real-time world events visualization platform that aggregates tweets about breaking events (natural disasters, protests, concerts, sports) using location intelligence, clusters them geographically, and displays them on an interactive heatmap map. Unique value proposition: Filters signal from social media noise using NLP event classification and spatial clustering - showing only verified, location-specific events instead of raw tweets. This solves the critical problem of information overload during breaking news situations for emergency responders, journalists, and travelers.\n\nWhy needed: Current social media platforms lack spatial context for real-time events. During crises like natural disasters, critical information gets buried in timelines. Global Pulse provides immediate geographic awareness that can save lives and optimize resource allocation.\n\nDevelopment worth: Built with zero external dependencies (fully containerized), this prototype demonstrates commercial viability for media organizations (real-time news dashboards) and emergency services (crisis monitoring). The spatial clustering algorithm alone represents novel utility.\n\n2. Architecture & Technology Decisions\n\nMonolith vs microservices: Monolith (single FastAPI application) because event processing pipeline (Twitter ingestion → NLP → geocoding → clustering → API) represents a single bounded context with low operational complexity for MVP.\n\nLanguage/framework: Python 3.11 + FastAPI 0.104.1 + SQLModel 0.0.13 + spaCy 3.7.4 (small English model). Justification: Async I/O for Twitter API handling, type safety via Pydantic models, and spaCy's lightweight NLP capabilities for event classification.\n\nData store: SQLite 3.45.1 with SQLModel ORM (embedded in /app/app.db). Justification: Zero-configuration transactional storage matching development constraints; sufficient for demo-scale data.\n\nCaching/performance: In-memory LRU cache (functools.lru_cache) for geocoding results and spaCy NLP pipeline. Justification: Eliminates redundant geocoding/NLP for same location/text during clustering.\n\nVerification strategy:\n- FastAPI: Run 'uvicorn app.main:app --port 8000' and verify OpenAPI docs at /docs via curl (manual run)\n- SQLite: Confirm 'app.db' creation with 'ls /app/app.db' after startup (manual inspection)\n- spaCy: Validate model download in pyproject.toml via 'python -c \"import spacy; assert spacy.load(\\\"en_core_web_sm\\\"); print(\\\"OK\\\")\"' (manual build)\n\n3. Security Design\n\nAuthentication: None (public read-only access) - data is intentionally non-sensitive public event information.\n\nEncryption: Not implemented (data is public domain).\n\nInput validation: Pydantic models for all API inputs + strict JSON parsing + spaCy-based NLP sanitization (removes PII from event descriptions).\n\nVerification strategy: Manual inspection of schemas.py for validation rules + unit test forcing invalid inputs through the API to verify rejection (test_events_api.py).\n\n4. Project Skeleton & File Layout\n\n/usr/src/project/\n├── event-backend\n│   ├── pyproject.toml\n│   ├── poetry.lock\n│   ├── app\n│   │   ├── __init__.py\n│   │   ├── main.py\n│   │   ├── config.py\n│   │   ├── models.py\n│   │   ├── schemas.py\n│   │   ├── services\n│   │   │   ├── __init__.py\n│   │   │   ├── twitter.py\n│   │   │   ├── nlp.py\n│   │   │   ├── geocoding.py\n│   │   │   ├── clustering.py\n│   │   │   └── event_processor.py\n│   │   └── api\n│   │       ├── __init__.py\n│   │       └── endpoints\n│   │           ├── __init__.py\n│   │           └── events.py\n│   ├── tests\n│   │   ├── __init__.py\n│   │   ├── test_twitter.py\n│   │   ├── test_geocoding.py\n│   │   ├── test_clustering.py\n│   │   └── test_events_api.py\n│   └── .env.example\n└── event-web\n    ├── package.json\n    ├── vite.config.ts\n    ├── index.html\n    ├── src\n    │   ├── main.tsx\n    │   ├── App.tsx\n    │   ├── components\n    │   │   └── HeatmapMap.tsx\n    │   └── services\n    │       └── api.ts\n    └── public\n\nVerification strategy: Run 'cd /usr/src/project && tree -a' and compare output against specified structure (manual inspection).\n\n5. Module-by-Module Creation Strategy\n\nBackend modules:\n- app.main: Initializes FastAPI app, scheduler, and service dependencies.\n  Public: app = FastAPI()\n  Verification: Manual run 'python -c \"from app.main import app\"' (no error)\n\n- app.services.twitter: Abstract Twitter client with mock implementation.\n  Public: class TwitterClient(ABC): async def fetch_events(...); FakeTwitterClient()\n  Verification: Unit test test_twitter.py validating fake client returns 5+ events\n\n- app.services.geocoding: Geocoding service with cache.\n  Public: async def geocode_cached(location: str) \n  Verification: Unit test testing cache hit/miss with 100ms tolerance\n\n- app.services.clustering: Spatial clustering of events.\n  Public: def cluster_events(events: list[Event], radius_m: int)\n  Verification: Manual run of __main__ in clustering.py with sample data\n\n- app.api.endpoints.events: Heatmap API endpoint.\n  Public: @router.get(\"/map\") async def get_heatmap()\n  Verification: Manual run and curl /map endpoint checking GeoJSON structure\n\nFrontend modules:\n- src/services/api.ts: Fetches heatmap data.\n  Public: fetchHeatmap(): Promise<GeoJSON>\n  Verification: Unit test mocking fetch and validating output type\n\n- src/components/HeatmapMap.tsx: Renders Leaflet heatmap.\n  Public: <HeatmapMap data={geojson} />\n  Verification: Manual inspection of marker clustering implementation\n\n6. Dependency & Build Management\n\nBackend (pyproject.toml):\n[tool.poetry.dependencies]\npython = \"3.11.9\"\nfastapi = \"0.104.1\"\nuvicorn = \"0.29.0\"\nsqlmodel = \"0.0.13\"\nhttpx = \"0.27.0\"\nspacy = \"3.7.4\"\nen-core-web-sm = {url = \"https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl\"}\n\n[tool.poetry.dev-dependencies]\npytest = \"7.4.3\"\naioresponses = \"0.7.4\"\npytest-asyncio = \"0.23.5\"\n\nFrontend (package.json):\n\"dependencies\": {\"leaflet\": \"1.9.4\", \"react\": \"18.2.0\", \"react-dom\": \"18.2.0\", \"react-leaflet\": \"4.2.1\", \"leaflet.heat\": \"0.2.0\"}\n\"devDependencies\": {\"vite\": \"5.0.0\", \"@vitejs/plugin-react\": \"4.0.0\", \"typescript\": \"5.0.0\"}\n\nBuild sequence:\n1. Backend: poetry install && python -m spacy download en_core_web_sm\n2. Frontend: npm install\n\nVerification: 'poetry install' and 'npm install' must exit 0 (manual build)\n\n7. Local Simulation & Stubbing Plan\n\n- Twitter API:\n  Stub: FakeTwitterClient returns hardcoded events with timestamps and location strings\n  Verification: test_twitter.py unit test checking event count and schema\n\n- Geocoding service:\n  Stub: FakeGeocodingService with predefined coordinates for \"Paris\", \"Tokyo\", etc.\n  Verification: test_geocoding.py testing known city coordinates\n\n- Event clustering:\n  Stub: Deterministic test data with events in concentric circles\n  Verification: test_clustering.py checking cluster density matches input radius\n\n8. Completion Definition\n\nProject is 100% complete when:\n1. All unit tests pass: 'poetry run pytest' (backend) and 'npm run build' (frontend) exit 0\n2. Backend runs without error: 'poetry run uvicorn app.main:app --port 8000'\n3. API verification: curl http://localhost:8000/map returns valid GeoJSON with \"type\":\"FeatureCollection\"\n4. Frontend verification: curl http://localhost:5173 contains 'id=\"map-container\"' and 'data-count=\"5\"'\n5. Spatial verification: Fake event locations cluster correctly (visually confirmed via browser navigation)
